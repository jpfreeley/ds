{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 07 Day 03 (20160224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Problem #1\n",
    "```\n",
    "text= ['It was the best of times, it was the worst of times.','My name is Inigo Montoya.You killed my father. Prepare to die.', 'Too weird to live, too rare to die!']\n",
    "```\n",
    "1) Using sklearn.feature_extraction.text CountVectorizer function, (also fit and transform) convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "You will get a sparse matrix of output. ex:\n",
    "```\n",
    "(0, 0) 1 (0, 5) 2 (0, 11) 2 (0, 14) 2 (0, 15) 2 (0, 18) 2 (0, 20) 1 ... ... ...\n",
    "```\n",
    "Can you explain what each row of this matrix represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = ['It was the best of times, it was the worst of times.',\n",
    "          'My name is Inigo Montoya.You killed my father. Prepare to die.', \n",
    "          'Too weird to live, too rare to die!']\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# X.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x22 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t2\n",
      "  (0, 18)\t2\n",
      "  (0, 14)\t2\n",
      "  (0, 0)\t1\n",
      "  (0, 11)\t2\n",
      "  (0, 15)\t2\n",
      "  (0, 20)\t1\n",
      "  (1, 9)\t2\n",
      "  (1, 10)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 21)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 1)\t1\n",
      "  (2, 16)\t2\n",
      "  (2, 1)\t1\n",
      "  (2, 17)\t2\n",
      "  (2, 19)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 13)\t1\n"
     ]
    }
   ],
   "source": [
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(min_df=1, stop_words = 'english', analyzer = 'word', strip_accents = None)\n",
    "X2 = vectorizer2.fit(corpus)\n",
    "print X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'best',\n",
       " u'die',\n",
       " u'father',\n",
       " u'inigo',\n",
       " u'killed',\n",
       " u'live',\n",
       " u'montoya',\n",
       " u'prepare',\n",
       " u'rare',\n",
       " u'times',\n",
       " u'weird',\n",
       " u'worst']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'best': 0,\n",
       " u'die': 1,\n",
       " u'father': 2,\n",
       " u'inigo': 3,\n",
       " u'killed': 4,\n",
       " u'live': 5,\n",
       " u'montoya': 6,\n",
       " u'prepare': 7,\n",
       " u'rare': 8,\n",
       " u'times': 9,\n",
       " u'weird': 10,\n",
       " u'worst': 11}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.vocabulary_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Problem #2\n",
    "\n",
    "This function is boring:\n",
    "```\n",
    "def square(x):\n",
    "    return x * x\n",
    "    \n",
    "square(5)\n",
    "## 25\n",
    "```\n",
    "\n",
    "Write a decorator called talky so that when you run this:\n",
    "```\n",
    "@talky\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "answer = square(5)\n",
    "```\n",
    "\n",
    "You get the following output:\n",
    "```\n",
    "Oh hi!\n",
    "The result sure is 25!\n",
    "```\n",
    "\n",
    "Extension: Write a decorator talky_with, so that when you run this:\n",
    "```\n",
    "@talky_with(\"Aaron\")\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "answer = square(5)\n",
    "```\n",
    "\n",
    "You get the following output:\n",
    "```\n",
    "Oh hi! I'm Aaron.\n",
    "The result sure is 25!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh hi!\n",
      "The result sure is 25\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "def talky(func):\n",
    "    def func_wrapper(x):\n",
    "        return 'Oh hi!\\nThe result sure is {0}'.format(func(x))\n",
    "    return func_wrapper\n",
    "\n",
    "greeting = talky(square)\n",
    "\n",
    "print greeting(5)\n",
    "# answer = square(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "talky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>lorem ipsum, John dolor sit amet</p>\n"
     ]
    }
   ],
   "source": [
    "def get_text(name):\n",
    "   return \"lorem ipsum, {0} dolor sit amet\".format(name)\n",
    "\n",
    "def p_decorate(func):\n",
    "   def func_wrapper(name1):\n",
    "       return \"<p>{0}</p>\".format(func(name1))\n",
    "   return func_wrapper\n",
    "\n",
    "my_get_text = p_decorate(get_text)\n",
    "\n",
    "print my_get_text(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.func_wrapper>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_get_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>lorem ipsum, John dolor sit amet</p>\n"
     ]
    }
   ],
   "source": [
    "get_text = p_decorate(get_text)\n",
    "\n",
    "print get_text(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
